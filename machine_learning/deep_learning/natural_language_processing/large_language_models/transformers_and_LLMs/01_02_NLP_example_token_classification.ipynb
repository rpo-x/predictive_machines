{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Inspired by \"Transformers and LLMs\" CM295 2025 (Stanford Univ.)",
   "id": "60b2ef0b5947c0d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Alright. Let's move to an example for named entity recognition (NER) (token classification):\n",
    "\n",
    "Predict (or classify) named entities into pre-defined categories. For this, we can use a DistilBERT model fine-tuned for NER, such as dslim/distilbert-NER (fine-tuned on CoNLL-2003). Datasets like CoNLL-2003 provide annotations for each token in a so called BIO format.\n",
    "\n",
    "To make this more clear, let's code it. Predict the categories of each token for \"Tim Cook presented the new iPhone in Las Vegas on Tuesday.\". "
   ],
   "id": "b7fb8dee975d5750"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T13:26:57.467851Z",
     "start_time": "2025-12-08T13:26:57.215826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "MODEL_NAME = \"dslim/distilbert-NER\"\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    classifier = pipeline(\n",
    "        task=\"token-classification\",\n",
    "        model=MODEL_NAME,\n",
    "        framework=\"pt\",\n",
    "    )\n",
    "\n",
    "    text = \"Tim Cook presented the new iPhone in Las Vegas on Tuesday.\"\n",
    "    result = classifier(text)  # pipeline returns a list of dictionaries\n",
    "\n",
    "    for token in result:\n",
    "        print(f\"Token: {token['word']}\")\n",
    "        print(f\"BIO tag: {token['entity']}\")\n",
    "        print(f\"Softmax probability:{token['score']:.6f}\") \n",
    "        print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "d48e6ea649ae6442",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: Tim\n",
      "BIO tag: B-PER\n",
      "Softmax probability:0.998844\n",
      "\n",
      "Token: Cook\n",
      "BIO tag: I-PER\n",
      "Softmax probability:0.998934\n",
      "\n",
      "Token: iPhone\n",
      "BIO tag: B-MISC\n",
      "Softmax probability:0.780839\n",
      "\n",
      "Token: Las\n",
      "BIO tag: B-LOC\n",
      "Softmax probability:0.997057\n",
      "\n",
      "Token: Vegas\n",
      "BIO tag: I-LOC\n",
      "Softmax probability:0.997060\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The token \"Tim\" is categorised as entity (BIO tag) \"B-PER\", \"Cook\" as \"I-PER\", and \"iPhone\" as \"B-MISC\". \"B-PER\" stands for \"Begin-Person\", i.e. it indicates that this token marks the beginning of a PERSON entity. \"I-PER\" stands for \"Inside-Person\", i.e. the token continues the same entity. \"B-MISC\" stands for \"Begin-Miscellaneous\", i.e. it indicates that this token marks the beginning of a MISC (OTHER) entity. \"O\" stands for \"Outside\" any entity, i.e. the token is not part of any entity, and when such a tag appears after a B- or I-tag, it signifies that the preceding entity span has ended.\n",
    "\n",
    "To make this more clear, let us merge predictions for individual tokens into predictions for spans (span is defined as a continuous segment of text formed by one or more consecutive tokens):\n"
   ],
   "id": "8536d3ea039b00dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T13:26:58.582419Z",
     "start_time": "2025-12-08T13:26:58.354896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "MODEL_NAME = \"dslim/distilbert-NER\"\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    classifier = pipeline(\n",
    "        task=\"token-classification\",\n",
    "        model=MODEL_NAME,\n",
    "        framework=\"pt\",\n",
    "        aggregation_strategy=\"simple\",  # merge token-level predictions into full word/entity spans\n",
    "    )\n",
    "\n",
    "    text = \"Tim Cook presented the new iPhone in Las Vegas on Tuesday.\"\n",
    "    result = classifier(text) # pipeline returns a list of dictionaries\n",
    "\n",
    "    for entity in result:\n",
    "        print(f\"Entity: {entity['word']}\")\n",
    "        print(f\"Group: {entity['entity_group']}\")\n",
    "        print(f\"Softmax probability: {entity['score']:.6f}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "898da776ec989865",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Tim Cook\n",
      "Group: PER\n",
      "Softmax probability: 0.998889\n",
      "\n",
      "Entity: iPhone\n",
      "Group: MISC\n",
      "Softmax probability: 0.780839\n",
      "\n",
      "Entity: Las Vegas\n",
      "Group: LOC\n",
      "Softmax probability: 0.997058\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Nice! The model successfully assigned PER, MISC and LOC to the entities \"Tim Cook\", \"iPhone\" and \"Las Vegas\". You may wonder what about \"Tuesday\". CoNLL-2003 does not annotate any kind of date as a named entity, therefore it ignores it. If I would like to predict / classify dates, then I could select e.g., a DistilBERT model fine-tuned on ontonotes5 which provides 18 entities. \n",
    "\n",
    "Let's code this."
   ],
   "id": "35799d9930f75f29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T13:26:59.580642Z",
     "start_time": "2025-12-08T13:26:59.171088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "MODEL_NAME = \"nickprock/distilbert-finetuned-ner-ontonotes\"\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    classifier = pipeline(\n",
    "        task=\"token-classification\",\n",
    "        model=MODEL_NAME,\n",
    "        framework=\"pt\",\n",
    "        aggregation_strategy=\"simple\",  # enable word-level named entities\n",
    "    )\n",
    "\n",
    "    text = \"Tim Cook presented the new iPhone in Las Vegas on Tuesday.\"\n",
    "    result = classifier(text) # pipeline returns a list of dictionaries (one per input)\n",
    "\n",
    "    for entity in result:\n",
    "        print(f\"Entity: {entity['word']}\")\n",
    "        print(f\"Type: {entity['entity_group']}\")\n",
    "        print(f\"Softmax probability: {entity['score']:.6f}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "de76116fe5ba124d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Tim Cook\n",
      "Type: PERSON\n",
      "Softmax probability: 0.999755\n",
      "\n",
      "Entity: iPhone\n",
      "Type: PRODUCT\n",
      "Softmax probability: 0.996051\n",
      "\n",
      "Entity: Las Vegas\n",
      "Type: GPE\n",
      "Softmax probability: 0.999699\n",
      "\n",
      "Entity: Tuesday\n",
      "Type: DATE\n",
      "Softmax probability: 0.999402\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Alright. Using the model fine-tuned on ontonotes5, the entity \"Tuesday\" is now successfully identified / classified as \"DATE\" with a probability of 0.999402.",
   "id": "60a8c9d1c3defb11"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Before we continue with an example for machine translation (text generation), I want to make clear that the previously introduced metrics (accuracy, precision, recall, F1) also apply to NER. The difference is that in NER these metrics are computed at the token/label level rather than at the sentence/label level, because NER assigns one BIO label per token.",
   "id": "2730060450e2f69e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Perfect!. Move on.",
   "id": "37fcbdcd16dfa20b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
